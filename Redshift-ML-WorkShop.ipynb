{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redshift ML ワークショップ \n",
    "---\n",
    "\n",
    "### ワークショップの概要\n",
    "本ワークショップでは、Amazon SageMaker Notebook Instances 上で動作する Jupyter ノートブックを使用します。このワークショップでは、3 種類のユーザーのペルソナに基づいて 3 つのラボを取り上げます。   \n",
    "1. **データアナリスト - 機械学習にはあまり精通していないユーザー**  \n",
    "2. **高度なデータアナリスト - 機械学習にも多少精通しているユーザー**  \n",
    "3. **データサイエンティスト -  機械学習のエキスパート**  \n",
    "\n",
    "\n",
    "### ラボのコンポーネント\n",
    "    \n",
    "* __Jupyter Notebook__:  \n",
    "あなたは今、Jupyter ノートブックの中にいます。これは、様々な種類のコードを実行し、その結果を見ながら対話型で確認することができる探索的な環境です。このワークショップでは、3 つのラボがそれぞれ 1 つのノートブックになっています。これらのノートブックは、各ラボの上部にある目次からアクセスできます。\n",
    "\n",
    "* __Amazon SageMaker Notebook Instance__:  \n",
    "このノートブックは、Amazon SageMakerノートブックインスタンス上で実行されています。これは、フルマネージドの Amazon EC2 インスタンスで、事前に設定された Jupyter ノートブックサーバと、`conda`ライブラリのセットを持っています。このワークショップのラボに必要な依存関係はすべてすでに存在しています。\n",
    "\n",
    "* __`conda` Python Kernel__:  \n",
    "カーネルは、インタラクティブなコードを受け取って実行し、ユーザーに出力を返すプロセスです。ノートブックのフロントエンドは，カーネルのバックエンドと通信します。このワークショップでは、`conda_python3`カーネルを使用します。\n",
    "\n",
    "[Project Jupyter]: https://jupyter.org/\n",
    "[SageMaker example notebooks]: https://github.com/awslabs/amazon-sagemaker-examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips:\n",
    " \n",
    "* 灰色の `code` のセルを上から下への順に実行していってください\n",
    "* 各セルには、実行すると何が起こるかを説明するタイトルテキストがあります\n",
    "* 最新のブラウザであれば動作する見込みですが、 Chrome の利用をを推奨します\n",
    "* ネットワークの接続性が悪いと、ノートブックの操作に若干の遅れが生じることがあります\n",
    "* セルが実行されると、左側のテキストが `In [*]:` に変わります\n",
    "* セルのコードが終了すると、左側のテキストが `In [19]:` に変わります \n",
    "    * 数字はセルが実行された順番を示します\n",
    "* **最後に** - セルの再実行は自由です \n",
    "    * セルを複数回実行したり、順番を間違えたり、再実行しても問題はありません"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. お客様のテストアカウント固有の情報を修正\n",
    "Redshift クラスターにアクセスするための認証情報を設定します\n",
    "このステップでは、`host_name` を Redshift クラスターの `hostname` に置き換えてください\n",
    "\n",
    "また、このノートブックに必要な python のライブラリをいくつかインストールします\n",
    "\n",
    "-----\n",
    "**期待されるアウトプット**: なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"user_name\": \"awsuser\",\n",
      "  \"password\": \"Awsuser123\",\n",
      "  \"host_name\": \"redshift-ml-demo.cehdaz7u3h70.us-west-2.redshift.amazonaws.com\",\n",
      "  \"port_num\": \"5439\",\n",
      "  \"db_name\": \"dev\"\n",
      "}\n",
      "Requirement already satisfied: psycopg2-binary in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.8.6)\n",
      "Requirement already satisfied: sqlalchemy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.3.13)\n",
      "Requirement already satisfied: simplejson in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (3.17.2)\n",
      "Requirement already satisfied: ipython-sql in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.4.0)\n",
      "Requirement already satisfied: ipython>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython-sql) (7.12.0)\n",
      "Requirement already satisfied: sqlparse in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython-sql) (0.4.1)\n",
      "Requirement already satisfied: ipython-genutils>=0.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: prettytable<1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython-sql) (0.7.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython-sql) (1.15.0)\n",
      "Requirement already satisfied: sqlalchemy>=0.6.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython-sql) (1.3.13)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (0.14.1)\n",
      "Requirement already satisfied: pygments in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (2.5.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (51.1.2)\n",
      "Requirement already satisfied: backcall in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (0.1.0)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (4.4.1)\n",
      "Requirement already satisfied: pexpect in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (4.3.3)\n",
      "Requirement already satisfied: pickleshare in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (3.0.3)\n",
      "Requirement already satisfied: parso>=0.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jedi>=0.10->ipython>=1.0->ipython-sql) (0.5.2)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql) (0.1.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pexpect->ipython>=1.0->ipython-sql) (0.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "\n",
    "echo \"{\n",
    "  \\\"user_name\\\": \\\"awsuser\\\",\n",
    "  \\\"password\\\": \\\"Awsuser123\\\",\n",
    "  \\\"host_name\\\": \\\"redshift-ml-demo.cehdaz7u3h70.us-west-2.redshift.amazonaws.com\\\",\n",
    "  \\\"port_num\\\": \\\"5439\\\",\n",
    "  \\\"db_name\\\": \\\"dev\\\"\n",
    "}\" > redshift-ml-workshop.creds\n",
    "\n",
    "cat redshift-ml-workshop.creds\n",
    "\n",
    "pip install psycopg2-binary\n",
    "pip install sqlalchemy \n",
    "pip install simplejson\n",
    "pip install ipython-sql\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Redshift クラスターへの接続とクエリの実行\n",
    "Redshift の接続を管理するために、sqlalchemy と ipython-sql の Python ライブラリを使用します\n",
    "このテストが完了すると、ラボの残りの部分に進むことができます\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "接続するために、 `hostname` の部分をクラスターエンドポイント名で置き換えます\n",
    "\n",
    "**サンプルアウトプット**:\n",
    "`current_user`\t`version`\n",
    "awsuser\tPostgreSQL 8.0.2 on i686-pc-linux-gnu, compiled by GCC gcc (GCC) 3.4.2 20041017 (Red Hat 3.4.2-6.fc3), Redshift 1.0.23274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "\n",
    "%sql postgresql+psycopg2://awsuser:Awsuser123@hostname:5439/dev\n",
    "#SELECT current_user, version();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg2://awsuser:***@redshift-ml-demo.cehdaz7u3h70.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>current_user</th>\n",
       "        <th>version</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>awsuser</td>\n",
       "        <td>PostgreSQL 8.0.2 on i686-pc-linux-gnu, compiled by GCC gcc (GCC) 3.4.2 20041017 (Red Hat 3.4.2-6.fc3), Redshift 1.0.23274</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('awsuser', 'PostgreSQL 8.0.2 on i686-pc-linux-gnu, compiled by GCC gcc (GCC) 3.4.2 20041017 (Red Hat 3.4.2-6.fc3), Redshift 1.0.23274')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT current_user, version();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - データアナリストユーザー \n",
    "---\n",
    "\n",
    "### データセットの情報: ###\n",
    "### 銀行のマーケティングデータセット ###\n",
    "\n",
    "このデータは、ポルトガルの銀行機関のダイレクトマーケティングキャンペーンに関連するものです。このマーケティングキャンペーンは、電話での問い合わせが基本でした。商品（銀行の定期預金）を申し込む（「はい」）か、申し込まない（「いいえ」）かを確認するために、同じ顧客に複数回接触することがしばしばありました\n",
    "\n",
    "この分類のシナリオのゴールは、顧客が定期預金 （変数 y) を申し込むかどうか (yes/no) を予測することです\n",
    "\n",
    "### 属性情報 / 入力変数 / 銀行の顧客データ: ###\n",
    "1 - age (numeric)   \n",
    "2 - job  \n",
    "3 - marital   \n",
    "4 - education   \n",
    "5 - default  \n",
    "6 - housing  \n",
    "7 - loan  \n",
    "8 - contact \n",
    "9 - month  \n",
    "10 - day_of_week  \n",
    "11 - duration  \n",
    "12 - campaign  \n",
    "13 - pdays  \n",
    "14 - previous  \n",
    "15 - poutcome  \n",
    "16 - emp.var.rate  \n",
    "17 - cons.price.idx  \n",
    "18 - cons.conf.idx  \n",
    "19 - euribor3m  \n",
    "20 - nr.employed  \n",
    "\n",
    "出力変数 :  \n",
    "21 - y - 顧客は定期預金を契約していますか? (binary: 'yes','no')  \n",
    "\n",
    "\n",
    "**参考:** https://archive.ics.uci.edu/ml/datasets/bank+marketing\n",
    "    \n",
    "サンプルデータセットは `bank_details_training` と `bank_details_inference` テーブルに既にロードされています\n",
    "\n",
    "また、デフォルトの実行時間(90分)で作成されたモデルが Redshift クラスターにあらかじめ組み込まれています。このワークショップでは、待ち時間を短縮するために、`MAX_RUNTIME` オプションを `９００ 秒` に設定して、修正版の create model を実行します\n",
    "\n",
    "推論クエリには、事前に作成されたモデルによって作成された SQL 関数を使用します\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ユースケース 1 の CREATE MODEL の変更 - データアナリストユーザー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- Create model for bank marketing use case with max runtime 900 secs -- */\n",
    " CREATE MODEL model_bank_marketing_v2\n",
    "FROM (\n",
    "    SELECT age\n",
    "        ,job\n",
    "        ,marital\n",
    "        ,education\n",
    "        ,\"default\"\n",
    "        ,housing\n",
    "        ,loan\n",
    "        ,contact\n",
    "        ,month\n",
    "        ,day_of_week\n",
    "        ,duration\n",
    "        ,campaign\n",
    "        ,pdays\n",
    "        ,previous\n",
    "        ,poutcome\n",
    "        ,emp_var_rate\n",
    "        ,cons_price_idx\n",
    "        ,cons_conf_idx\n",
    "        ,euribor3m\n",
    "        ,nr_employed\n",
    "        ,y\n",
    "    FROM bank_details_training\n",
    "    ) TARGET y \n",
    "FUNCTION func_model_bank_marketing_v2 \n",
    "IAM_ROLE '<< replace IAM role arn >>' \n",
    "SETTINGS(S3_BUCKET '<< replace S3 output bucket >>', MAX_RUNTIME 900);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ユースケース 1 の Show MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- Show all models -- */\n",
    " SHOW model ALL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- Show prebuilt model for bank marketing  -- */\n",
    " SHOW model model_bank_marketing;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- Show model for bank marketing created during the workshop -- */\n",
    " SHOW model model_bank_marketing_v2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデル `model_bank_marketing` の推論/精度の確認\n",
    "ここでは、モデルの精度をチェックするためのクエリを実行します。ここでは、事前に構築されたモデルによって作成された関数を推論に使用し、推論テーブル `bank_details_inference` のデータセットに対して実行します。ワークショップで作成したモデルが作成した関数に対しても、自由に実行してみてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "/* -- Check accuracy for bank marketing using prebuilt model function  -- */\n",
    " WITH infer_data\n",
    "AS (\n",
    "\tSELECT y AS actual\n",
    "\t\t,func_model_bank_marketing(age, job, marital, education, \"default\", housing, loan, contact, month, day_of_week, duration, campaign, pdays, previous, poutcome, emp_var_rate, cons_price_idx, cons_conf_idx, euribor3m, nr_employed) AS predicted\n",
    "\t\t,CASE \n",
    "\t\t\tWHEN actual = predicted\n",
    "\t\t\t\tTHEN 1::INT\n",
    "\t\t\tELSE 0::INT\n",
    "\t\t\tEND AS correct\n",
    "\tFROM bank_details_inference\n",
    "\t)\n",
    "\t,aggr_data\n",
    "AS (\n",
    "\tSELECT SUM(correct) AS num_correct\n",
    "\t\t,COUNT(*) AS total\n",
    "\tFROM infer_data\n",
    "\t)\n",
    "SELECT (num_correct::FLOAT / total::FLOAT) AS accuracy\n",
    "FROM aggr_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定期預金を申し込む顧客数と申し込まない顧客数の予測\n",
    "このクエリは、推論テーブル `bank_details_inference` のデータセットに対して実行しています"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 予測クエリのサンプルアウトプット\n",
    "\n",
    "```sql\n",
    "     deposit_prediction     | count\n",
    "----------------------------+-------\n",
    " Yes-will-do-a-term-deposit |  5362\n",
    " No-term-deposit            | 35826\n",
    "(2 rows)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "/* -- Predict whether the customer will do a term deposit or not  -- */\n",
    "WITH term_data AS ( SELECT func_model_bank_marketing( age,job,marital,education,\"default\",housing,loan,contact,month,day_of_week,duration,campaign,pdays,previous,poutcome,emp_var_rate,cons_price_idx,cons_conf_idx,euribor3m,nr_employed) AS predicted \n",
    "FROM bank_details_inference )\n",
    "SELECT \n",
    "CASE WHEN predicted = 'Y'  THEN 'Yes-will-do-a-term-deposit'\n",
    "     WHEN predicted = 'N'  THEN 'No-term-deposit'\n",
    "     ELSE 'Neither' END as deposit_prediction,\n",
    "COUNT(1) AS count\n",
    "from term_data GROUP BY 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - 高度なデータアナリストユーザー \n",
    "----  \n",
    "\n",
    "### データセットの情報: ####\n",
    "### アイリスデータセット ###\n",
    "\n",
    "こちらはおそらくパターン認識の文献の中で最もよく知られているデータベースでしょう。フィッシャーの論文はこの分野の古典であり、現在でも頻繁に参照されています。(例えば、Duda & Hart を参照してください。) \n",
    "このデータセットには、それぞれ 50 個のインスタンスからなる 3 つのクラスが含まれており、各クラスはアイリスの種類を表しています。1 つのクラスは他の 2 つのクラスから線形分離可能ですが、後者はお互いに線形分離できません\n",
    "\n",
    "*予測される属性:* アヤメのクラス\n",
    "\n",
    "\n",
    "属性情報:\n",
    "\n",
    "1. がくへんの長さ (cm)\n",
    "2. がくへんの幅 (cm)\n",
    "3. 花びらの長さ (cm)\n",
    "4. 花びらの幅 (cm)\n",
    "5. クラス:\n",
    "-- Iris Setosa\n",
    "-- Iris Versicolour\n",
    "-- Iris Virginica */\n",
    "\n",
    "ユーザーは、create model の中で `PROBLEM_TYPE` と `OBJECTIVE` とった情報を指定してモデルを作成できます \n",
    "\n",
    "SageMaker Autopilot は、すべてのアルゴリズムを試すのではなく、ユーザーが指定した `PROBLEM_TYPE` と `OBJECTIVE` に応じたアルゴリズムを選択します \n",
    "\n",
    "この例では、 `PROBLEM_TYPE` として `multiclass classification` を指定します\n",
    "\n",
    "SageMaker Autopilot でサポートされているすべての PROBLEM_TYPE についてはこちらを参照 - https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-automate-model-development-problem-types.html \n",
    "\n",
    "`OBJECTIVE` は  `accuracy` を指定します。 このメトリクスは、機械学習システムの予測品質を測定するために使用されます\n",
    "\n",
    "*デフォルト値:* MSE: 回帰用, F1: for バイナリ分類用, Accuracy: for マルチクラス分類用\n",
    "\n",
    "サポートされるすべての \"objectives\" は以下を参照: https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_MODEL.html#r_user_guidance_create_model\n",
    "\n",
    "\n",
    "サンプルデータセットは `iris_data_train` と `iris_data_test` テーブルに既にロードされています\n",
    "\n",
    "また、デフォルトの実行時間(90分)で作成されたモデルが Redshift クラスターにあらかじめ組み込まれています。このワークショップでは、待ち時間を短縮するために、`MAX_RUNTIME` オプションを `９００ 秒` に設定して、修正版の create model を実行します\n",
    "\n",
    "推論クエリには、事前に作成されたモデルによって作成された SQL 関数を使用します\n",
    "\n",
    "実行前に、 `IAM role` と `S3 bucket` は必ず変更してください\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 高度なデータアナリストユーザー向けの Create Model ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%sql` not found.\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "/* -- Create model for iris use case - with max runtime 900 secs -- */\n",
    " CREATE MODEL model_iris_v2\n",
    "FROM (\n",
    "SELECT \n",
    "   Id,\n",
    "   SepalLengthCm,\n",
    "   SepalWidthCm,\n",
    "   PetalLengthCm,\n",
    "   PetalWidthCm,\n",
    "   Species\n",
    "FROM iris_data_train\n",
    ")\n",
    "TARGET Species \n",
    "FUNCTION func_model_iris_v2 IAM_ROLE '<< replace IAM role arn >>' \n",
    "PROBLEM_TYPE multiclass_classification \n",
    "OBJECTIVE 'accuracy' \n",
    "SETTINGS (S3_BUCKET '<< replace S3 output bucket >>', MAX_RUNTIME 900);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ユースケース 2 のアイリスデータセットのための Show model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- show pre built model for iris -- */\n",
    " SHOW model model_iris;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "/* -- show model for model created during the workshop -- */\n",
    " SHOW model model_iris_v2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデル `model_iris` の推論/精度の確認\n",
    "ここでは、モデルの精度を確認するためのクエリを実行します。ここでは、事前に作成したモデルが作成した関数を推論に使用し、推論テーブル `iris_data_test` のデータセットに対して実行します \n",
    "\n",
    "ワークショップで作成したモデルが作成した関数に対しても、自由に実行してみてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- Inference query for iris data set -- */\n",
    "WITH infer_data AS (\n",
    "    SELECT Species AS label,\n",
    "        func_model_iris(Id, SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm) AS predicted,\n",
    "        CASE WHEN label is NULL THEN NULL ELSE label END AS actual,\n",
    "        CASE WHEN actual = predicted THEN 1::INT\n",
    "        ELSE 0::INT END AS correct\n",
    "    FROM iris_data_test\n",
    "),\n",
    "aggr_data AS (\n",
    "    SELECT SUM(correct) as num_correct, COUNT(*) as total FROM infer_data\n",
    ")\n",
    "SELECT (num_correct::float/total::float) AS accuracy FROM aggr_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テストデータセットを使ってアイリスの花のクラスを予測 \n",
    "推論テーブル `iris_data_set` のデータセットに対して、このクエリを実行します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 予測のサンプルアウトプット\n",
    "\n",
    "```sql\n",
    "dev-# from class_data GROUP BY 1;\n",
    "  class_distribution   | count\n",
    "-----------------------+-------\n",
    " Class-Iris-versicolor |    82\n",
    " Class-Iris-setosa     |    81\n",
    " Class-Iris-virginica  |    88\n",
    "(3 rows)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- Predict the Iris flower class -- */ \n",
    "WITH class_data AS ( SELECT func_model_iris( \n",
    "   Id,\n",
    "   SepalLengthCm,\n",
    "   SepalWidthCm,\n",
    "   PetalLengthCm,\n",
    "   PetalWidthCm) AS class \n",
    "FROM iris_data_test )\n",
    "SELECT \n",
    "CASE WHEN class = 'Iris-versicolor'  THEN 'Class-Iris-versicolor'\n",
    "     WHEN class = 'Iris-setosa'  THEN 'Class-Iris-setosa'\n",
    "     WHEN class = 'Iris-virginica'  THEN 'Class-Iris-virginica'\n",
    "     ELSE 'Class-Other' END as class_distribution,\n",
    "COUNT(1) AS count\n",
    "from class_data GROUP BY 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - データサイエンティスト / 機械学習エキスパート \n",
    "---\n",
    "\n",
    "### データセットの情報: ###\n",
    "\n",
    "物理的な測定からアワビの年齢を予測します。アワビの年齢を決定するには、貝殻を円錐形に切り取り、染色し、顕微鏡で輪の数を数えますが、これは退屈で時間のかかる作業です。年齢を予測するためには、より簡単に得られる他の測定方法を用います。この問題を解決するためには、気象パターンや場所（つまり食べ物の有無）など、さらなる情報が必要になることもあります\n",
    "\n",
    "元のデータから、値が欠落している例が削除され（大部分は予測値が欠落している）、連続値の範囲はANNで使用するためにスケーリングされています（200で割ることにより）\n",
    "\n",
    "\n",
    "属性情報:\n",
    "\n",
    "属性名、属性タイプ、測定単位、簡単な説明が与えられます。リングの数は、連続値として、または分類問題として予測する値です\n",
    "\n",
    "### 名前 / データ型 / 測定の単位 / 説明 ###\n",
    "---\n",
    "Sex / nominal / -- / M, F, and I (infant)  \n",
    "Length / continuous / mm / Longest shell measurement  \n",
    "Diameter / continuous / mm / perpendicular to length  \n",
    "Height / continuous / mm / with meat in shell  \n",
    "Whole weight / continuous / grams / whole abalone \n",
    "Shucked weight / continuous / grams / weight of meat  \n",
    "Viscera weight / continuous / grams / gut weight (after bleeding)  \n",
    "Shell weight / continuous / grams / after being dried  \n",
    "Rings / integer / -- / +1.5 gives the age in years  \n",
    "  \n",
    "*参考* : https://archive.ics.uci.edu/ml/datasets/Abalone  \n",
    "\n",
    "この例では、ユーザーは高度な機械学習エキスパートと想定され、Autopilot は使われず、直接 `preprocessors` や `hyper parameters` などの高度なプロパティを指定します \n",
    "\n",
    "\n",
    "このシナリオでは `MODEL_TYPE` , `OBJECTIVE`, `PREPROCESSORS` そして `HYPER PARAMETERS` を指定します\n",
    "\n",
    "すべてのサポートされたオプションはこちらを参照 - https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_MODEL.html#r_auto_off_create_model\n",
    "\n",
    "\n",
    "サンプルデータセットは `abalone_xgb_train` と `abalone_xgb_test` テーブルに既にロードされています\n",
    "\n",
    "`xgboost` を指定した create model を実行します。 ~15 分ほどかかります \n",
    "\n",
    "推論クエリには、モデルが作成したSQL関数を使用することができます\n",
    "\n",
    "create model を実行する前に、テーブルを作成してサンプルデータをロードします。COPY 文の中で、必ず `IAM role` を変更してください\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- Create table for xgboost model training -- */\n",
    "CREATE TABLE abalone_xgb_train (\n",
    "length_val float, \n",
    "diameter float, \n",
    "height float,\n",
    "whole_weight float, \n",
    "shucked_weight float, \n",
    "viscera_weight float,\n",
    "shell_weight float, \n",
    "rings int\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- Create table for xgboost model testing -- */\n",
    "CREATE TABLE abalone_xgb_test (\n",
    "length_val float, \n",
    "diameter float, \n",
    "height float,\n",
    "whole_weight float, \n",
    "shucked_weight float, \n",
    "viscera_weight float,\n",
    "shell_weight float, \n",
    "rings int\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- COPY for abalone_xgb_train -- */\n",
    "COPY abalone_xgb_train FROM 's3://redshift-downloads/redshift-ml/workshop/xgboost_abalone_data/train/' REGION 'us-east-1' IAM_ROLE '<< replace IAM role arn >>' IGNOREHEADER 1 CSV;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- COPY for abalone_xgb_test -- */\n",
    "COPY abalone_xgb_test FROM 's3://redshift-downloads/redshift-ml/workshop/xgboost_abalone_data/test/' REGION 'us-east-1' IAM_ROLE '<< replace IAM role arn >>' IGNOREHEADER 1 CSV;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- Create model -- */\n",
    "CREATE MODEL model_abalone_xgboost_regression \n",
    "FROM (SELECT\n",
    "      length_val,\n",
    "      diameter,\n",
    "      height,\n",
    "      whole_weight,\n",
    "      shucked_weight,\n",
    "      viscera_weight,\n",
    "      shell_weight,\n",
    "      rings\n",
    "     FROM abalone_xgb_train)\n",
    "TARGET Rings \n",
    "FUNCTION func_model_abalone_xgboost_regression \n",
    "IAM_ROLE '<< replace IAM role arn >>' \n",
    "AUTO OFF \n",
    "MODEL_TYPE xgboost \n",
    "OBJECTIVE 'reg:squarederror' \n",
    "PREPROCESSORS 'none' \n",
    "HYPERPARAMETERS DEFAULT EXCEPT (NUM_ROUND '100') \n",
    "SETTINGS (S3_BUCKET '<< S3 bucket >>');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost のための Show model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW model model_abalone_xgboost_regression;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデルの推論/精度を確認 ####\n",
    "MSE/RMSE [低いほどよい]: 回帰問題では、精度のため Mean Squared Error / Root Mean Squared Error を実行します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- Accuracy query -- */\n",
    "WITH infer_data AS (\n",
    "    SELECT Rings AS label, func_model_abalone_xgboost_regression(\n",
    "Length_val, Diameter, Height, Whole_weight, Shucked_weight, Viscera_weight,\n",
    "Shell_weight\n",
    ") AS predicted,\n",
    "    CASE WHEN label is NULL THEN 0 ELSE label END AS actual\n",
    "    FROM abalone_xgb_test\n",
    ")\n",
    "SELECT SQRT(AVG(POWER(actual - predicted, 2))) AS rmse FROM infer_data;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 採取するアワビ種の年齢層を予測 (テストテーブルでの実行) #### \n",
    "\n",
    "サンプルアウトプット\n",
    "\n",
    "```sql\n",
    "     age_group     | count\n",
    "-------------------+-------\n",
    " age_between_10_20 |   589\n",
    " age_between_5_10  |   247\n",
    " age_5_and_under   |     1\n",
    " age_over_20       |     1\n",
    "(4 rows)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- Prediction query -- */\n",
    "WITH age_data AS ( SELECT func_model_abalone_xgboost_regression( length_val, \n",
    "                                               diameter, \n",
    "                                               height, \n",
    "                                               whole_weight, \n",
    "                                               shucked_weight, \n",
    "                                               viscera_weight, \n",
    "                                               shell_weight ) + 1.5 AS age\n",
    "FROM abalone_xgb_test )\n",
    "SELECT \n",
    "CASE WHEN age  > 20 THEN 'age_over_20'\n",
    "     WHEN age  > 10 THEN 'age_between_10_20'\n",
    "     WHEN age  > 5  THEN 'age_between_5_10'\n",
    "     ELSE 'age_5_and_under' END as age_group,\n",
    "COUNT(1) AS count\n",
    "from age_data GROUP BY 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# デバッグのためのシステムテーブル #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/* -- stv_ml_model_info -- */\n",
    "SELECT * FROM stv_ml_model_info WHERE model_name='model_abalone_xgboost_regression';\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
